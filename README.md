# AI Comedian: LSTM Text Generation

## ğŸ¤– Project Overview

**AI Comedian** is a Natural Language Processing (NLP) comparison study exploring the creative potential of Recurrent Neural Networks (RNNs). It employs **Long Short-Term Memory (LSTM)** networks to generate humorous content (jokes) and performs sentiment classification to analyze the "mood" of generated text.

## ğŸ”‘ Key Features

- **Sequence Modeling**: Implements LSTMs (and potential variants) for character-level or word-level text generation.
- **Data Pipeline**: Robust preprocessing to clean and tokenize raw text corpora.
- **Sentiment Analysis**: Classification module to evaluate the sentiment polarity of jokes.
- **Comparative Study**: Evaluates the coherence and humor of machine-generated text against human baselines.

## ğŸ› ï¸ Tech Stack & Skills

- **Language**: Python
- **DL Framework**: TensorFlow / Keras (Implied) or PyTorch
- **NLP Techniques**: Tokenization, Padding, Embeddings, Recurrent Layers
- **Data**: Pandas, NumPy

## ğŸ’¡ Innovation

Generating humor is considered an "AI-Hard" problem. This project tackles the challenge of **context retention** in long sequences, demonstrating advanced understanding of RNN architectures and the difficulties of capturing semantic nuances like irony or punchlines.

## ğŸ“‚ Structure

- `generation/`: Models for creating text.
- `classification/`: Models for sentiment analysis.
- `preprocessing/`: Data cleaning utilities.
